{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Networks \n",
    "\n",
    "## What is it?\n",
    "\n",
    "\n",
    "\n",
    "## When is it used?\n",
    "\n",
    "* Face recognition\n",
    "* Play video games\n",
    "\n",
    "## Why is it used, or why isnt it used?\n",
    "\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "* Matches parts of an image rather than the whole thing (in a literal sense). For example, if you wanted to classify an X from an O, an CNN would try and identify subareas of an image that offer this distinction.\n",
    "\n",
    "**Convolution**\n",
    "\n",
    "Features in CNN's are represented my small images, for example, a 3x3 pixeled image. These features act as subsets of the larger image. And if we want to match an image we filter this image across the bigger image. During this filtering process the pixels are compared and a new number is computed to denote the score, `score=np.sum(np.mult(image_patch, filter))/n_pixels`. A score of 1 for example can denote a perfect match between the filter and the the image subset. The process of multiplication compares individual pixels as being representative or not, the process of adding and dividing is finding the mean, to coorespond to how well a match evolved over the filter. Therefore, the process of iterating this filter across the entire image produces a new image that signals where our filter matched well. This iterative process is also known as _convolution_. We also use this symbol: $\\circledast$ between a filter and image as a shorthand to represent it, because it is used across several different features or filters. A convolutional layer is a stack of these filtered images.\n",
    "\n",
    "**Pooling**\n",
    "\n",
    "The second thing we do is called pooling. Pooling is the process of shrinking the image stack (the convolutional layer). Basically, it is the same process like before (where we take in some size filter iterative through the image and do some operation with the filter and the image). The goal here is to compress a filtered image. So we want a smaller image, want to effective represent something similar. To do this, we select a window size, stride, and walk the window accross the image and take the maximum value. The window size is the size of the filter, and the stride is the step size we take in the image. A larger window size the smaller the resulting image, but the more information we lose. Same idea with stride. This process is called max pooling. Pooling accomplishes two things. One it makes it more convienient to work because it is smaller. Secondly, it represents a similar image that is insensitive to position (since the maximum is taken). This makes sense to do because real features of a image could exist in similiar setting, but position perhaps in a different light, or a little bit large in one direction vs the other. Running this process across all filtered images produces a _pooling layer_.\n",
    "\n",
    "**Normalization**\n",
    "\n",
    "Normalization replaces all negative values in a layer to zero. This has mathematical consequences. For one, it treat areas of an image that were matching to all be equally not matching. This operation as a result produces a new kind of layer called a ReLU layer.\n",
    "\n",
    "**Putting it all Together**\n",
    "\n",
    "Stack each layer -> Convolution, ReLU, Pooled so that the output of one layer become the input on another. The process of layer stacking can be done in many different combinations. For example, we begin with the original image, run several convolutions, and then for each of this convolutions run a ReLu, another convolution on these ReLu's, etc. \n",
    "\n",
    "`Input->conv->relu->conv->relu->pool->conv->relu->pool`\n",
    "\n",
    "Layer across layer produces more and more abstract images, by virtue of the operations done across these layers.\n",
    "\n",
    "The final layer in our network is called a _fully connected layer_. The fully connected layer is a single list. This list is produced by flattening each filtered image and stacking these together to form a single list. The values of this list represent the weight of which they classify one image of another. And the weight of the alternative (binary) classification would be 1-weight. \n",
    "\n",
    "So now, we can pass an image through the network, and the result will tell use whether class A or class B is favored more depending on the weight. Average the weights, take the maximum and your got your selection of classification.\n",
    "\n",
    "\n",
    "**How the Weights of the Final Fully Connected Layer Are Obtained**\n",
    "\n",
    "The values of the final fully connected layer ultimately decide the final decision to the classifier network. The algorithm that trains the network is called back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
