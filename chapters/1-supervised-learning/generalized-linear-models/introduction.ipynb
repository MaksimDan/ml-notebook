{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## What is Regression?\n",
    "\n",
    "Regression in general is the relationship between the mean of an output variable $y$ and some input variable $x$. Because it models from input data, this is a supervised machine learning method. It is also worth noting that regression specifically deals with continuous data. A discrete output is otherwise known as classification. In both cases of regressions and classification will create define feature space or zones of prediction. Of course, we have to calcuate our way to get there, but all of it already exists as a consequence of the model.\n",
    "\n",
    "The goal with regression to determine the optimal relationship between input (features) and output (dependent variable of interest).\n",
    "\n",
    "\n",
    "## Types of Regression\n",
    "\n",
    "* Univariate - use a single feature to make a prediction. $\\hat{y} = c_0w_0 + c_1w_1$, or more classically known as $y=mx+b$.\n",
    "* Multivariate - multiple features are used to make a prediction. This is a generalization of the univarate model, and will be discussed before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Linear Regression\n",
    "\n",
    "Include models where the target value  is a linear combination of the input variables. There are no squared, or exponential terms. The model is strictly a linear combination ($c_p$ are the constants).\n",
    "\n",
    "$$\\hat{y_i}(w, x_i)= w_0 + w_1x_1 + \\dots + w_nx_n$$\n",
    "\n",
    "* $w$ = weight vector that defines the model\n",
    "* $x_i$ = input feature vector (row $i$ in dataset) describing the characteristics of the model.\n",
    "* $\\hat{y_i}$ = predicted value as a function of the features (input) and learned weights.\n",
    "* $n$ = number of features\n",
    "\n",
    "What we have control over are the weights. We refer to $w_0$ as the intercept, and $w = (w_1 \\dots w_n)$ as models coefficients. More generally, we write it as.\n",
    "\n",
    "Using matrix notation, we can rewrite the above as \n",
    "\n",
    "$$\\hat{y} = h_w(x) = w^Tx$$\n",
    "\n",
    "* $h$ is the hypothesis function, as to describe the numerical estimation of the model.\n",
    "* $x$ is the same feature vector as before. \n",
    "* $w$ is same weight vector as before, this time transposed in order to be inline with linear algebraic rule of vector dot product. $w$ is of dimension $(nx1)$, and $x$ is of dimension $(1xn)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
