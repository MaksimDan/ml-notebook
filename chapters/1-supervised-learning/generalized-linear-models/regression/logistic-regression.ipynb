{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression or (logit regression), is a probabilistic classifier much like Naive Bayes. It classifiers the probability of a model falling between one of two classes and can generalize this strategy to perform a multiclassification as well.\n",
    "\n",
    "Logistic regression takes the same exact approach as linear regression, both train for a linear set of weighted features. The major differences come from the logistic interpretation with the sigmoid function on top of the model.\n",
    "\n",
    "## The Mechanics of Logistic Regression\n",
    "\n",
    "$z$ is defined as the weighted sum of features, with bias weight $w_0$\n",
    "\n",
    "$$z = w_0 + x_1 w_1 + x_2 w_2 + x_3 w_3 + \\dots + x_n w_n = \\sum_{i=0}^n x_i w_i = x w^T$$\n",
    "\n",
    "These weighted sum of inputs are a part of another composite function y.\n",
    "\n",
    "$$\\hat{y} = P(y=1|x) = \\frac{1}{1 + exp(-x w^T)}$$\n",
    "\n",
    "**What do we have so far?**\n",
    " \n",
    "$z$ is the weighted sum of features. This tells us that given some sample of $x$ (which is our data), and learned weights $w$, value $z$ is produced that can either be really high or low. Our data cannot change, so the value of $x$ cannot change. The only number have control over is $w$, which once set, is going to immediately define the behavior of everything else. For example, we can imagine that if a feature is unimportant, then its weight would be close to zero effectively ignoring the feature altogether since it has no affect on $z$.\n",
    "\n",
    "Next, $z$ gets truncated into a value between 0 and 1 by the sigmoid function in order to be to become reinterpreted as a probability. First of all, why do we want this? We already have a way numerically capturing an input $x$ framed in the context of $w$. To answer this question, we need to get reminded of our goal. We want make a classification on $x$. This means that we need a way to map $x \\mapsto [0, 1]$. $z$ currently just maps to $(-\\infty, +\\infty)$. Using a remapping into sigmoid ($\\sigma$) gives as a reasonable way to make a classification. If its close to 1, we'll probably predict and 1, and vise-versa.\n",
    "\n",
    "Ok, so there are an infinite number of equations that can remap the infinity domain between $[0, 1]$. Why sigmoid? The answer to this is probably more complicated then the way I'll frame it but lets think about the properties is provides.\n",
    "\n",
    "* If $z$ is high, then $\\sigma$ is 1.\n",
    "* If $z$ is low, then $\\sigma$ is 0.\n",
    "* If $z$ is 0, then $\\sigma$ is .5.\n",
    "\n",
    "Reinterpretting this into a higher context, this is allow for $w$ to push $x$ to either one or the other end of the number line. A binary classification. Ok, but what are the consequences of giving it an exponential shape? And why is it mirrored?\n",
    "\n",
    "Sigmoid is mirrored vertically, because we want to fairly reflect $w$ into making an either negative or positive classification. The exponential property is a little more tricky. What this essentially allows for is the mapping two really easily skew towards 0 or 1. Theres not much room in between, considering the full domain $x$ can map to. Give a set of training examples that have an output of 0 or 1, the goal is to formulate an equation that predicts negative examples to as close to 0 as possible and positive examples to as close to 1 as possible. To answer this in a deeper level, we'll have to understand how sigmoid fits into the context of the loss function.\n",
    "\n",
    "\n",
    "**The Sigmoid Function**\n",
    "\n",
    "The logistic function, or sigmoid function, which contains an \"S\" shaped curve - squishing _any_ input value, and outputting a value between 0 and 1. In logistic regression, the sigmoid makes our final prediction.\n",
    "\n",
    "$$\\hat{y} = P(y=1|x) = \\sigma(x) = \\frac{1}{1 + exp(-x w^T)}$$\n",
    "\n",
    "$\\hat{y}$ is usually a notation for \"predicted y\", our estimation for the real $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1091bdf60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from myutils.draw.math import sigmoid\n",
    "\n",
    "\n",
    "sigmoid(fig_size=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding $w$**\n",
    "\n",
    "At this point, we have a way of justifying a prediction using $w$. But how can we find $w$ in an efficient way?\n",
    "\n",
    "To find $w$, we need a way to characterize $X$ (our input) in relation our output $\\hat{y}$. Doing this models a loss function in the process. What makes a loss function characteristic is how it reflect a correct a correct and incorrect classification.\n",
    "\n",
    "$$J(w) = \\frac{1}{m} \\sum_{i=1}^m \\frac{1}{2} (\\hat{y}(x^{(i)}) - y^{(i)})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (i) represents the ith training sample.\n",
    "* $J$ is a function of the input vector $w$, and represent the overall cost or performance of the model.\n",
    "* $y^{(i)}$ is the real classification (either 0 or 1)\n",
    "* $\\hat{y}(x^{(i)})$ is the result of our decision function that came from the sigmoid. This is the part that we want to be as close to 0 or 1, depending on true classification. The larger our prediction is from the true difference, the larger our error.\n",
    "    * This difference is squared, so that larger differences are \"punished\" to a larger extent that smaller differences are.\n",
    "* Finally the differences are averaged across $m$ samples.\n",
    "* The $\\frac{1}{2}$ is just a constant that effects every single classification, so relative difference does not change, so it is ok to put down. We'll see how this makes things mathematically more convenient later on.\n",
    "* $J(w)$ is a non-convex function, meaning that there are possibly many local suboptimums, and no convergence to a _single_ global minimum.\n",
    "    * For this reason, the cost function is redefined while maintaining the properties we discussed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "$$J(w) = \\frac{1}{m} \\sum_{i=1}^m -[(y^{(i)}log(\\hat{y}(x^{(i)})) + (1-y^{(i)})log(\\hat{y}(x^{(i)}))]$$\n",
    "\n",
    "This is just a compact way of saying this: (they both equate to the same thing). It is written in a compact way to avoid having to deal with piece-wise derivatives later.\n",
    "\n",
    "$$\n",
    "    J(w)= \n",
    "\\begin{cases}\n",
    "    -log(\\hat{y}(x^{(i)})), & \\text{if } y^{(i)} = 1\\\\\n",
    "    -log(1-\\hat{y}(x^{(i)})), & \\text{if } y^{(i)} = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "* Lets try to understand why this is a logical thing to do. And why it still works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10fba51d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from myutils.draw.math import plt_2d_functions\n",
    "\n",
    "\n",
    "plt_2d_functions([lambda x: -np.log(x), lambda x: -np.log(1-x)], np.arange(0.01, .999, .01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above models $-log(x)$ and $-log(1-x)$ when $0 \\leq x \\leq 1$ (since x is limited by the output from sigmoid). These functions are mirrored on $x=.5$, so they measure the distance from 0 and 1 to the same degrees. The cost is infinitely high on both accounts incorrect classification. The complement is true vise-versa.\n",
    "\n",
    "Additionally:\n",
    "* The function is convex for the optimal model weights can be found.\n",
    "* The derivative of logarithmic summations is a great simplification. $\\frac{d}{dx}log_a(x) = \\frac{\\frac{d}{dx}(x)}{xln(a)}$, so $\\frac{d}{dx} \\sum_{i=0}^m log_a(x^{(i)}) = \\frac{m}{xln(a)}$\n",
    "    * When if we assume natural logarithms, then $\\frac{d}{dx}log_e(x) = \\frac{\\frac{d}{dx}(x)}{xln(e)} = \\frac{1}{x}$\n",
    "    \n",
    "To understand how to train the logistic regression model via gradient descent, refer to this [Chapter](todo). This chapter in particular will derive the conclusions we need for gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it All Together\n",
    "\n",
    "Recall that our goal is to find the _average_ cost among all the samples, rather than just a single sample. This is because we want to capture how the performance of the weights against a generalize set of inputs.\n",
    "\n",
    "Fortunately for us, all the differentiation is since the sum of derivatives act independently from one another.\n",
    "\n",
    "$$\\nabla w_j = \\frac{\\partial}{\\partial w_j} J(w) = \\frac{1}{m} \\sum_{i=0}^m (-y^{(i)} + \\hat{y}(z^{(i)})) \\cdot x_j^{(i)}$$\n",
    "\n",
    "And finally, our update rule becomes $w := w + \\eta \\frac{1}{m} \\sum_{i=0}^m (y^{(i)} - \\hat{y}(z^{(i)})) \\cdot x^{(i)}$, where $\\eta$ is the learning rate. Notice the distributive flip in signs for simplification. Now that we have our update rule for the weights, after training through a substantial number of samples, we obtain our learn set of weights.\n",
    "\n",
    "Using these weights, we can perform classification based on our original function from the start. \n",
    "\n",
    "$$\n",
    "    y'= \\frac{1}{1+exp(-w^{T}x')} =\n",
    "\\begin{cases}\n",
    "    1, \\text{if } y' \\geq 0.5 \\\\ \n",
    "    0, \\text{if } y' < 0.5 \\\\ \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Selecting 0.5 as the decision threshold is the default choice because it is the furthest distance from each class equally. This parameter can be changed of course, for example - to maximize auc under roc. It also can be adjusted manually to reduce false positive when the context demands it. For example, if the the decision threshold is .7, then the positive class has to be a lot more likely in order for the classification to take place. A similar effect can be seen in the opposite direction. For example, consider classifying patients on whether or not they have cancer. Naturally also false negatives (patients who where classified as not having cancer, but in reality did) would be bad news.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Digression 1: Fitting an Intercept\n",
    "\n",
    "When we fit an intercept or 'bias' to a model, what we are really doing is providing the flexibility of the model to move an additional dimension. Consider for example $y=mx$ that has a fixed slope rotating about $(0,0)$. Adding a bias $b$, provides the equation to move freely about the vertical axis $y=mx+b$.\n",
    "\n",
    "In optimization, $b$ is really just a made up feature that is independent from the training samples. So suppose we have n features, $x_1, x_2, x_3, \\dots, x_n$, and an associated set of weights for every feature $w_1, w_2, w_3, \\dots, w_n$. If we want to add an additional feature $x_0$, we just need to treat it as 1 or $x_0^0 = 1$, now the associated weight $w_0$ becomes $w_0*(x_0^0)$ which simplifies to just $w_0$. So as a consequence of adding $x_0$ to be a constantly 1, we introduce an additive leverage into the model that always to be whatever it wants to be.\n",
    "\n",
    "In linear algebra, this accounts to just stacking an additional column vector.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{d1} & x_{d2} & x_{d3} & \\dots  & x_{dn}\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "    1 & x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    1 & x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    1 & x_{d1} & x_{d2} & x_{d3} & \\dots  & x_{dn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "# Note: this implementation assumes sparse input matrix X\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    objective: squash input\n",
    "    :param x: np.array - inputs\n",
    "    :return: np.array - output\n",
    "    \"\"\"\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def _get_prediction(X, weights):\n",
    "    \"\"\"\n",
    "    objective: compute y-hat given the samples and trained weights\n",
    "    y_hat = 1 / 1 + exp(X*w^T)\n",
    "    :param X: np.matrix - training sample features\n",
    "    :param weights: np.array - trained weights for each X\n",
    "    :return: np.array - probability of classification\n",
    "    \"\"\"\n",
    "    return sigmoid(X@weights)\n",
    "\n",
    "\n",
    "def _gd_single(X_train, y_train, weights, eta):\n",
    "    \"\"\"\n",
    "    objective: single gradient descent step down\n",
    "    w := w + eta/m sum_{0 to m} (y_i - y_hat(z_i)) * x_i\n",
    "    :param X_train: np.matrix - training samples\n",
    "    :param y_train: np.array - true classifications\n",
    "    :param eta: float - learning rate\n",
    "    \"\"\"\n",
    "    y_hat = _get_prediction(X_train, weights)\n",
    "    m = y_train.shape[0]\n",
    "    weights_delta = X_train.T@(y_train - y_hat)\n",
    "    weights += (eta / float(m)) * weights_delta\n",
    "    return weights\n",
    "\n",
    "\n",
    "def _get_cost(X, y, weights):\n",
    "    \"\"\"\n",
    "    objective: compute the cost J(w)\n",
    "    J(w) = 1/m sum_{0 to m} -[(y_i)log(y_hat(x_i)) + (1-y_i)log(y_hat(x_i))]\n",
    "    :param X: np.matrix - samples\n",
    "    :param y: np.array - classifications\n",
    "    :param weights: np.array - trained weights for each X\n",
    "    :return: float - average cost all training samples\n",
    "    \"\"\"\n",
    "    y_hat = _get_prediction(X, weights) \n",
    "    # (indexing from matrix to vector)\n",
    "    return np.mean(-y * np.log(y_hat) - (1-y) * np.log(1-y_hat))\n",
    "\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, max_iter, eta, fit_intercept=False, keep_history=False):\n",
    "    \"\"\"\n",
    "    objective: train a linear regression model\n",
    "    :param X_train: np.matrix - training samples\n",
    "    :param y_train: np.array - training classifications\n",
    "    :param max_iter: int - number of gd steps\n",
    "    :param eta: float - learning rate (vector scaler)\n",
    "    :param fit_intercept: bool - include w_0 or not\n",
    "    \"\"\"\n",
    "    # stack column vector for intercept\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        X_train = sparse.hstack((intercept, X_train))\n",
    "    # initialize weights to the number of rows, if including w_0 \n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "    w_history, cost = [], []\n",
    "    for i in range(max_iter):\n",
    "        # update the weights, print the updated cost every 1000 iterations\n",
    "        weights = _gd_single(X_train, y_train, weights, eta)\n",
    "        if keep_history:\n",
    "            w_history.append(weights)\n",
    "            cost.append(_get_cost(X_train, y_train, weights))\n",
    "    if keep_history:\n",
    "        return np.asarray(w_history), np.asarray(cost)\n",
    "    else:\n",
    "        return np.asarray(weights)\n",
    "\n",
    "\n",
    "def predict(X, weights):\n",
    "    \"\"\"\n",
    "    objective: entry point function get predictions of X, given trained weights\n",
    "    :param X: np.matrix - samples\n",
    "    :param weights: np.array - feature weights\n",
    "    \"\"\"\n",
    "    # if the number of columsn dont match, then add the intercept column\n",
    "    if X.shape[1] != weights.shape[0]:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = sparse.hstack((intercept, X))\n",
    "    return _get_prediction(X, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification weights after 1000 iterations\n",
      "[ 0.4541707   1.97448332 -2.44069422]\n"
     ]
    }
   ],
   "source": [
    "# training sample\n",
    "X_train = np.array([[6, 7],\n",
    "                    [2, 4],\n",
    "                    [3, 6],\n",
    "                    [4, 7],\n",
    "                    [1, 6],\n",
    "                    [5, 2],\n",
    "                    [2, 0],\n",
    "                    [6, 3],\n",
    "                    [4, 1],\n",
    "                    [7, 2]])\n",
    "X_train = sparse.csr_matrix(X_train)\n",
    "y_train = np.array([0,0,0,0,0,1,1,1,1,1])\n",
    "\n",
    "weights = train_logistic_regression(X_train, y_train, max_iter=1000, eta=0.1, \n",
    "                                    fit_intercept=True, keep_history=False)\n",
    "print('Classification weights after 1000 iterations')\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 0.9999478000270096 -> True\n",
      "prediction: 0.007439911157784815 -> False\n",
      "prediction: 0.980865201041308 -> True\n",
      "prediction: 0.02080847023610398 -> False\n"
     ]
    }
   ],
   "source": [
    "# testing sample\n",
    "X_test = np.array([[6, 1],\n",
    "                   [1, 3],\n",
    "                   [3, 1],\n",
    "                   [4, 5]])\n",
    "X_test = sparse.csr_matrix(X_test)\n",
    "\n",
    "pred = predict(X_test, weights)\n",
    "class_pred = pred >= 0.5\n",
    "for p, c in zip(pred, class_pred):\n",
    "    print(f'prediction: {p} -> {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click Through Prediction with Logistic Regression and Gradient Descent\n",
    "\n",
    "Running our model on click data found on: https://www.kaggle.com/c/avazu-ctr-prediction/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myutils.config import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "# read in data\n",
    "DATA_DIR = join(config['data_dir'], 'click-rate-prediction')\n",
    "click_df = pd.read_csv(join(DATA_DIR, 'train.csv'), nrows=2500)\n",
    "\n",
    "# drop unnecessary columns for now\n",
    "click_df.drop(['id', 'hour', 'device_id', 'device_ip'], axis=1, inplace=True)\n",
    "\n",
    "# label encode\n",
    "click_df = click_df.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# split X and y into np matricies explicitly\n",
    "col_names = list(click_df)\n",
    "X_names, y_names = list(filter(lambda name: name != 'click', col_names)), ['click']\n",
    "X, y = np.array(click_df[X_names]), np.array(click_df[y_names])\n",
    "\n",
    "# one hot encoding for categorical distance constaint\n",
    "X = OneHotEncoder(categories='auto').fit_transform(X)\n",
    "\n",
    "# split X and y into training and test sets\n",
    "y = y.reshape(1, len(y))[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 training iterations completed in 3.934 seconds\n",
      "The ROC AUC on testing set is: 0.700\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# learn the weights\n",
    "start_time = timeit.default_timer()\n",
    "weights, cost = train_logistic_regression(X_train, y_train, max_iter=10000, \n",
    "                                          eta=0.01, fit_intercept=True, keep_history=True)\n",
    "time_end = timeit.default_timer() - start_time\n",
    "print(f'10000 training iterations completed in {time_end:.3f} seconds')\n",
    "\n",
    "# test the performance of the classifier\n",
    "predictions = predict(X_test, weights[-1])\n",
    "auc_score = roc_auc_score(y_test, predictions)\n",
    "print(f'The ROC AUC on testing set is: {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1483</th>\n",
       "      <th>1484</th>\n",
       "      <th>1485</th>\n",
       "      <th>1486</th>\n",
       "      <th>1487</th>\n",
       "      <th>1488</th>\n",
       "      <th>1489</th>\n",
       "      <th>1490</th>\n",
       "      <th>1491</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.216595</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>-0.074967</td>\n",
       "      <td>-0.07259</td>\n",
       "      <td>-0.008316</td>\n",
       "      <td>-0.10686</td>\n",
       "      <td>-0.180198</td>\n",
       "      <td>-0.027291</td>\n",
       "      <td>-0.009106</td>\n",
       "      <td>-0.021985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013712</td>\n",
       "      <td>0.048743</td>\n",
       "      <td>-0.074682</td>\n",
       "      <td>-0.00784</td>\n",
       "      <td>0.127827</td>\n",
       "      <td>-0.008405</td>\n",
       "      <td>-0.150768</td>\n",
       "      <td>0.043158</td>\n",
       "      <td>-0.253059</td>\n",
       "      <td>0.680989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.216595</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>-0.074967</td>\n",
       "      <td>-0.07259</td>\n",
       "      <td>-0.008316</td>\n",
       "      <td>-0.10686</td>\n",
       "      <td>-0.180198</td>\n",
       "      <td>-0.027291</td>\n",
       "      <td>-0.009106</td>\n",
       "      <td>-0.021985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013712</td>\n",
       "      <td>0.048743</td>\n",
       "      <td>-0.074682</td>\n",
       "      <td>-0.00784</td>\n",
       "      <td>0.127827</td>\n",
       "      <td>-0.008405</td>\n",
       "      <td>-0.150768</td>\n",
       "      <td>0.043158</td>\n",
       "      <td>-0.253059</td>\n",
       "      <td>0.669472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.216595</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>-0.074967</td>\n",
       "      <td>-0.07259</td>\n",
       "      <td>-0.008316</td>\n",
       "      <td>-0.10686</td>\n",
       "      <td>-0.180198</td>\n",
       "      <td>-0.027291</td>\n",
       "      <td>-0.009106</td>\n",
       "      <td>-0.021985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013712</td>\n",
       "      <td>0.048743</td>\n",
       "      <td>-0.074682</td>\n",
       "      <td>-0.00784</td>\n",
       "      <td>0.127827</td>\n",
       "      <td>-0.008405</td>\n",
       "      <td>-0.150768</td>\n",
       "      <td>0.043158</td>\n",
       "      <td>-0.253059</td>\n",
       "      <td>0.658561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.216595</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>-0.074967</td>\n",
       "      <td>-0.07259</td>\n",
       "      <td>-0.008316</td>\n",
       "      <td>-0.10686</td>\n",
       "      <td>-0.180198</td>\n",
       "      <td>-0.027291</td>\n",
       "      <td>-0.009106</td>\n",
       "      <td>-0.021985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013712</td>\n",
       "      <td>0.048743</td>\n",
       "      <td>-0.074682</td>\n",
       "      <td>-0.00784</td>\n",
       "      <td>0.127827</td>\n",
       "      <td>-0.008405</td>\n",
       "      <td>-0.150768</td>\n",
       "      <td>0.043158</td>\n",
       "      <td>-0.253059</td>\n",
       "      <td>0.648224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.216595</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>-0.074967</td>\n",
       "      <td>-0.07259</td>\n",
       "      <td>-0.008316</td>\n",
       "      <td>-0.10686</td>\n",
       "      <td>-0.180198</td>\n",
       "      <td>-0.027291</td>\n",
       "      <td>-0.009106</td>\n",
       "      <td>-0.021985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013712</td>\n",
       "      <td>0.048743</td>\n",
       "      <td>-0.074682</td>\n",
       "      <td>-0.00784</td>\n",
       "      <td>0.127827</td>\n",
       "      <td>-0.008405</td>\n",
       "      <td>-0.150768</td>\n",
       "      <td>0.043158</td>\n",
       "      <td>-0.253059</td>\n",
       "      <td>0.638429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2        3         4        5         6  \\\n",
       "0 -0.216595  0.046137 -0.074967 -0.07259 -0.008316 -0.10686 -0.180198   \n",
       "1 -0.216595  0.046137 -0.074967 -0.07259 -0.008316 -0.10686 -0.180198   \n",
       "2 -0.216595  0.046137 -0.074967 -0.07259 -0.008316 -0.10686 -0.180198   \n",
       "3 -0.216595  0.046137 -0.074967 -0.07259 -0.008316 -0.10686 -0.180198   \n",
       "4 -0.216595  0.046137 -0.074967 -0.07259 -0.008316 -0.10686 -0.180198   \n",
       "\n",
       "          7         8         9    ...         1483      1484      1485  \\\n",
       "0 -0.027291 -0.009106 -0.021985    ...    -0.013712  0.048743 -0.074682   \n",
       "1 -0.027291 -0.009106 -0.021985    ...    -0.013712  0.048743 -0.074682   \n",
       "2 -0.027291 -0.009106 -0.021985    ...    -0.013712  0.048743 -0.074682   \n",
       "3 -0.027291 -0.009106 -0.021985    ...    -0.013712  0.048743 -0.074682   \n",
       "4 -0.027291 -0.009106 -0.021985    ...    -0.013712  0.048743 -0.074682   \n",
       "\n",
       "      1486      1487      1488      1489      1490      1491      cost  \n",
       "0 -0.00784  0.127827 -0.008405 -0.150768  0.043158 -0.253059  0.680989  \n",
       "1 -0.00784  0.127827 -0.008405 -0.150768  0.043158 -0.253059  0.669472  \n",
       "2 -0.00784  0.127827 -0.008405 -0.150768  0.043158 -0.253059  0.658561  \n",
       "3 -0.00784  0.127827 -0.008405 -0.150768  0.043158 -0.253059  0.648224  \n",
       "4 -0.00784  0.127827 -0.008405 -0.150768  0.043158 -0.253059  0.638429  \n",
       "\n",
       "[5 rows x 1493 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import seaborn as sns\n",
    "weights_df = pd.DataFrame(weights)\n",
    "weights_df['cost'] = cost\n",
    "weights_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Efficiency via Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gd_single(X_train, y_train, weights, eta):\n",
    "    \"\"\"\n",
    "    objective: single stochastic gradient deweights_deltascent step down\n",
    "    w := w + eta/m sum_{0 to m} (y_i - y_hat(z_i)) * x_i\n",
    "    :param X_train: np.matrix - training samples\n",
    "    :param y_train: np.array - true classifications\n",
    "    :param eta: float - learning rate\n",
    "    \"\"\"\n",
    "    # every example in this case updates the weights\n",
    "    # but the power comes from that fact that we will\n",
    "    # need fewer iterations to converage towards the minimum\n",
    "    for X_sample, y_sample in zip(X_train, y_train):\n",
    "        # gets a single prediction since we are iterating\n",
    "        # through every row, rather than passing a matrix\n",
    "        y_hat = _get_prediction(X_sample, weights)\n",
    "        weights_delta = X_sample.T@(y_sample - y_hat)\n",
    "        weights = weights + (eta * weights_delta).T\n",
    "    return weights\n",
    "\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, max_iter, eta, fit_intercept=False, keep_history=False):\n",
    "    \"\"\"\n",
    "    objective: train a linear regression model\n",
    "    :param X_train: np.matrix - training samples\n",
    "    :param y_train: np.array - training classifications\n",
    "    :param max_iter: int - number of gd steps\n",
    "    :param eta: float - learning rate (vector scaler)\n",
    "    :param fit_intercept: bool - include w_0 or not\n",
    "    \"\"\"\n",
    "    # to support row by row iteration for stochastic gradient descent\n",
    "    X_train = X_train.todense()\n",
    "\n",
    "    # stack column vector for intercept\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        X_train = np.hstack((intercept, X_train))\n",
    "    # initialize weights to the number of rows, if including w_0\n",
    "    weights = np.zeros(X_train.shape[1])\n",
    "    w_history, cost = [], []\n",
    "    for i in range(max_iter):\n",
    "        # update the weights, print the updated cost every 1000 iterations\n",
    "        weights = _gd_single(X_train, y_train, weights, eta)\n",
    "        if keep_history:\n",
    "            w_history.append(weights)\n",
    "            cost.append(_get_cost(X_train, y_train, weights))\n",
    "    if keep_history:\n",
    "        return np.asarray(w_history), np.asarray(cost)\n",
    "    else:\n",
    "        return np.asarray(weights)\n",
    "\n",
    "\n",
    "def predict(X, weights):\n",
    "    \"\"\"\n",
    "    objective: entry point function get predictions of X, given trained weights\n",
    "    :param X: np.matrix - samples\n",
    "    :param weights: np.array - feature weights\n",
    "    \"\"\"\n",
    "    # if the number of columsn dont match, then add the intercept column\n",
    "    X = X.todense()\n",
    "    if X.shape[1] != weights.T.shape[0]:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "    return _get_prediction(X, weights)\n",
    "\n",
    "\n",
    "def _get_prediction(X, weights):\n",
    "    \"\"\"\n",
    "    objective: compute y-hat given the samples and trained weights\n",
    "    y_hat = 1 / 1 + exp(X*w^T)\n",
    "    :param X: np.matrix - training sample features\n",
    "    :param weights: np.array - trained weights for each X\n",
    "    :return: np.array - probability of classification\n",
    "    \"\"\"\n",
    "    return sigmoid(X@np.asmatrix(weights).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the performance of the classifier, this time with only 5 iterations (compared to the previous 10000). Most the changes introduced in the code dealt with the need to work with a sparse matrix row by row. To deal with this, the sparse matrix was converted back to dense. It could be written more efficiently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 training iterations completed in 0.351 seconds\n",
      "The ROC AUC on testing set is: 0.702\n"
     ]
    }
   ],
   "source": [
    "# learn the weights\n",
    "start_time = timeit.default_timer()\n",
    "weights, cost = train_logistic_regression(X_train, y_train, max_iter=5, \n",
    "                                          eta=0.01, fit_intercept=True, keep_history=True)\n",
    "time_end = timeit.default_timer() - start_time\n",
    "print(f'5 training iterations completed in {time_end:.3f} seconds')\n",
    "\n",
    "# test the performance of the classifier\n",
    "predictions = predict(X_test, weights[-1])\n",
    "auc_score = roc_auc_score(y_test, predictions)\n",
    "print(f'The ROC AUC on testing set is: {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that both the performance improved with even less computational time. Lets try this with a larger sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a new, larger dataset\n",
    "click_df = pd.read_csv(join(DATA_DIR, 'train.csv'), nrows=10000)\n",
    "click_df.drop(['id', 'hour', 'device_id', 'device_ip'], axis=1, inplace=True)\n",
    "click_df = click_df.apply(LabelEncoder().fit_transform)\n",
    "col_names = list(click_df)\n",
    "X_names, y_names = list(filter(lambda name: name != 'click', col_names)), ['click']\n",
    "X, y = np.array(click_df[X_names]), np.array(click_df[y_names])\n",
    "X = OneHotEncoder(categories='auto').fit_transform(X)\n",
    "y = y.reshape(1, len(y))[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 training iterations completed in 1.559 seconds\n",
      "The ROC AUC on testing set is: 0.700\n"
     ]
    }
   ],
   "source": [
    "# learn the weights\n",
    "start_time = timeit.default_timer()\n",
    "weights, cost = train_logistic_regression(X_train, y_train, max_iter=5, \n",
    "                                          eta=0.01, fit_intercept=True, keep_history=True)\n",
    "time_end = timeit.default_timer() - start_time\n",
    "print(f'5 training iterations completed in {time_end:.3f} seconds')\n",
    "\n",
    "# test the performance of the classifier\n",
    "predictions = predict(X_test, weights[-1])\n",
    "auc_score = roc_auc_score(y_test, predictions)\n",
    "print(f'The ROC AUC on testing set is: {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating Decision Boundaries\n",
    "\n",
    "As we know, the output of a logistic model output a probability of a class. Lets show this visually using just one feature from the iris dataset to from a binary classification on one particular kind of iris flower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Decision Boundary for Petal Width Feature in Predicting Iris-Virginica Flower')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# create a binary logistic model\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, 3:]\n",
    "y = (iris[\"target\"] == 2).astype(np.int)\n",
    "\n",
    "# train\n",
    "log_reg = LogisticRegression(solver='lbfgs')\n",
    "log_reg.fit(X, y)\n",
    "\n",
    "# demo decision boundary\n",
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", label=\"Iris-Virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", label=\"Not Iris-Virginica\")\n",
    "plt.legend(loc=\"center left\", fontsize=14)\n",
    "plt.xlabel(\"Petal width (cm)\", fontsize=14)\n",
    "plt.ylabel(\"Probability\", fontsize=14)\n",
    "plt.title(\"Decision Boundary for Petal Width Feature in Predicting Iris-Virginica Flower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision bounadry lyes at the intersection of the curve (p=.5), where there is an equal probability for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Logistic Regression through Sci-kit Learn's SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielm/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# loss - the cost function (default == squared error)\n",
    "# penalty - regularization to avoid overfittng\n",
    "# learning_rate - the default learning rate is 'optimal', which makes the learning rate decreases as more\n",
    "#                 and more updates are taken (variable learning rate)\n",
    "sgd_lr = SGDClassifier(loss='log', penalty=None,\n",
    "                       fit_intercept=True, max_iter=5,\n",
    "                       learning_rate='constant', eta0=0.01)\n",
    "\n",
    "# test the performance\n",
    "sgd_lr.fit(X_train, y_train)\n",
    "predictions = sgd_lr.predict_proba(X_test)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, predictions)\n",
    "print(f'The ROC AUC on testing set is: {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Logistic Regression with Regularization\n",
    "\n",
    "By default scikit learn add an l2-penality, but this can be altered as well as tuned using $c$ (not $\\alpha$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielm/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# train the model with l1 regularization\n",
    "l1_feature_selector = SGDClassifier(loss='log', penalty='l1',\n",
    "                                    alpha=0.0001, fit_intercept=True,\n",
    "                                    max_iter=5, learning_rate='constant',\n",
    "                                    eta0=0.01)\n",
    "l1_feature_selector.fit(X_train, y_train)\n",
    "\n",
    "# test the performance\n",
    "predictions = l1_feature_selector.predict_proba(X_test)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, predictions)\n",
    "print(f'The ROC AUC on testing set is: {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features: 2820\n",
      "L1 subset features: 848\n"
     ]
    }
   ],
   "source": [
    "# now that we have the model trained, transform the dataset to select\n",
    "# the subset of features (and cooresponding data) from the original training set\n",
    "non_zero_features = l1_feature_selector.coef_[l1_feature_selector.coef_ != 0]\n",
    "print(f'Original features: {X_train.shape[1]}\\nL1 subset features: {len(non_zero_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top feature locations:\n",
      "[2787 2634 2791  544 1229 2792  340  710 2318  332]\n",
      "Top features:\n",
      "[0.2676457  0.2676457  0.27298015 0.27712119 0.28401015 0.29508706\n",
      " 0.29703416 0.2971603  0.31440656 0.33084284]\n",
      "\n",
      "Bottom feature locations:\n",
      "[2802 1684 2323  639  137  441 2532  716 2529  713]\n",
      "Bottom features:\n",
      "[-0.52964224 -0.45265284 -0.38691584 -0.36442899 -0.36442899 -0.33627522\n",
      " -0.31533644 -0.30064633 -0.28815729 -0.2797977 ]\n"
     ]
    }
   ],
   "source": [
    "# we can view the top most \"important\" and \"unimportant\" features\n",
    "argsorted_features = np.argsort(l1_feature_selector.coef_)\n",
    "\n",
    "bottom_feature_loc = argsorted_features[0][:10]\n",
    "top_feature_loc = argsorted_features[0][-10:]\n",
    "\n",
    "bottom_features = l1_feature_selector.coef_[0][bottom_feature_loc]\n",
    "top_features = l1_feature_selector.coef_[0][top_feature_loc]\n",
    "\n",
    "print('Top feature locations:')\n",
    "print(top_feature_loc)\n",
    "print('Top features:')\n",
    "print(top_features)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Bottom feature locations:')\n",
    "print(bottom_feature_loc)\n",
    "print('Bottom features:')\n",
    "print(bottom_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Large Scale Datasets with Online Learning\n",
    "\n",
    "With online learning, we can partition our dataset into minibatches, and produce a model from each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielm/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# grab a super large dataset\n",
    "click_df = pd.read_csv(join(DATA_DIR, 'train.csv'), nrows=1000000)\n",
    "click_df.drop(['id', 'hour', 'device_id', 'device_ip'], axis=1, inplace=True)\n",
    "click_df = click_df.apply(LabelEncoder().fit_transform)\n",
    "col_names = list(click_df)\n",
    "X_names, y_names = list(filter(lambda name: name != 'click', col_names)), ['click']\n",
    "X, y = np.array(click_df[X_names]), np.array(click_df[y_names])\n",
    "X = OneHotEncoder().fit_transform(X)\n",
    "y = y.reshape(1, len(y))[0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ |#                                                  | 0 Elapsed Time: 0:00:00/Users/danielm/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "| |   #                                               | 9 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online training completed in 0.400 seconds\n",
      "The ROC AUC on testing set is: 0.747\n"
     ]
    }
   ],
   "source": [
    "import progressbar\n",
    "import math\n",
    "\n",
    "# initiate a model\n",
    "sgd_lr = SGDClassifier(loss='log', penalty=None,\n",
    "                       fit_intercept=True, max_iter=1,\n",
    "                       learning_rate='constant', eta0=0.01)\n",
    "\n",
    "# create a pairwise iterator for indexing\n",
    "start, end, in_x_steps = 0, X_train.shape[0], 10\n",
    "offset = math.floor((end - start) / in_x_steps)\n",
    "my_iter = np.arange(start, end+offset, offset)\n",
    "bar = progressbar.ProgressBar()\n",
    "\n",
    "# online learning: mini-batch the model\n",
    "start_time = timeit.default_timer()\n",
    "for i, j in bar(zip(my_iter, my_iter[1:])):\n",
    "    X_train_sub, y_train_sub = X_train[i:j, :], y_train[i:j]\n",
    "    sgd_lr.partial_fit(X_train_sub, y_train_sub, classes=[0, 1])\n",
    "time_end = timeit.default_timer() - start_time\n",
    "print(f'Online training completed in {time_end:.3f} seconds')\n",
    "\n",
    "# test the performance of the classifier\n",
    "predictions = sgd_lr.predict_proba(X_test)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, predictions)\n",
    "print(f'The ROC AUC on testing set is: {auc_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression (aka Softmax Regression)\n",
    "\n",
    "### Making the Predictions\n",
    "\n",
    "Recall that in the binary case, we represented our model as \n",
    "\n",
    "$$P(y=1|x) = \\frac{1}{1 + exp(-x w^T)}$$\n",
    "\n",
    "which classifies an output as 1, given input x, parameterized by some set of weights to a value between 0 and 1. Naturally, since the probabilities must sum to 1, we inferred that\n",
    "\n",
    "$$P(y=0|x) = 1 - \\frac{1}{1 + exp(-x w^T)}$$\n",
    "\n",
    "In the K-model case we include a score function $s_k(x)$, which computes a score _vector_ for each class $k$. Notice its similiarities to above.\n",
    "\n",
    "$$s_k(x) = (w^k)^T \\cdot x$$\n",
    "\n",
    "So a weight vector is included per class. So we now have a big $W$ matrix. This weight matrix is the most crucial part, and is what we train to produce, using the data.\n",
    "\n",
    "| class | w_1  | w_2  | w_3  | . | . | . | w_k  |\n",
    "|-------|------|------|------|---|---|---|------| \n",
    "| 1     | w_11 | w_21 | w_31 | . | . | . | w_k1 | \n",
    "| 2     | w_12 |   .  |   .  | . | . | . | w_k2 | \n",
    "| 3     | w_13 |   .  |   .  | . | . | . | w_k3 | \n",
    "| .     | .    |   .  |   .  | . | . | . | .    | \n",
    "| .     | .    |   .  |   .  | . | . | . | .    | \n",
    "| .     | .    |   .  |   .  | . | . | . | .    | \n",
    "| k     | w_1n |   .  |   .  | . | . | . | w_kn | \n",
    "\n",
    "\n",
    "Then to compute the actual probability of a particular class, we take that score vector, and normalize it like this:\n",
    "\n",
    "$$\\hat{p_k} = P(y=k|x) = \\frac{exp(s_k(x))}{\\sum_{k=1}^K exp(s_k(x))}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensures that class $K$ (our target) given a particular input $x$ is normalized to a particular value between 0 and 1. \n",
    "\n",
    "Notice that $\\sum_{j=1}^K exp(s_j(x))$ in the denominator sums over all the weight vectors in order to normalizes the probability of the specific k class, $exp(s_j(x))$ between a value of 0 and 1.\n",
    "\n",
    "For example, if we were interested in the probability of class 1 occuring over the other 3 classes, our model would become\n",
    "\n",
    "$$\\hat{p_k} = P(y=1|x) = \\frac{exp(s_1(x))}{exp(s_1(x)) + exp(s_2(x)) + exp(s_3(x))}$$\n",
    "\n",
    "Conceptually, we have three possible events (1), (2) and (3), and so (1) + (2) + (3) must = 1 because they represented the entire probabilitiy space. Naturally then as (1) is weighted higher, then so will its probability of classification.\n",
    "\n",
    "So at this point we have a way of outputing the probability of a particular $x$. Now to wrap everything up, we need to actually produce a (single) classification, so in order to do that, we take argmax to return the class with the highest estimated probability.\n",
    "\n",
    "$$y' = \\text{argmax}_k P(y=k|x')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Process\n",
    "\n",
    "Our objective to produce a high probability for the target class, and low probability for the remaining other classes.\n",
    "\n",
    "To achieve this, the _cross entropy_ function is minimized. Notice how when k=2, the cost function is equivalent to that of logistic regression.\n",
    "\n",
    "$$J(W) = \\frac{-1}{m} \\sum_{i=1}^m \\sum_{k=1}^K 1\\{y^{(i)}=k\\} log(\\hat{p_k}^{(i)})$$\n",
    "\n",
    "\n",
    "**Understanding the cost function**\n",
    "\n",
    "The cost function many nested functions so lets back up and try to understand how this works. First of all, we can ignore the sum of K because all it does is identify what $k$ (class) matches with the actual class and zeros out everything else. This only happens once and zeros out the remaining occurances (just like in the binary case). The summation over $K$ is really just to identify the correct instance of the output class. What you get for example, is something like $0 + 0 + 0 + 0 + log(\\hat{p_k}^{(i)}) + \\dots + 0$. The zeros add no cost. Lets just chose a random class k=1. Now we can simplify this to:\n",
    "\n",
    "$$J(W) = \\frac{-1}{m} \\sum_{i=1}^m log(\\hat{p_1}^{(i)})$$\n",
    "\n",
    "The cost function iterates through all the training instances (of size m), and just returns the average of the error. So lets break it down once again and just look at a particular training example because it just repeated logic. Lets pick a random training instance i=2.\n",
    "\n",
    "$$J(W) = -log(\\hat{p_1}^{(2)})$$\n",
    "\n",
    "Now we know that $0 \\le log(\\hat{p_k}^{(i)}) \\le 1$ becuase $\\hat{p_k}^{(i)}$ is a normalized probability. Lets look at $-log(x)$ and see how this frames it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1170ba588>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XmYXFWd//H3t/f0Ur2vSSedTtLZISQhG5CwKRFRcFRARBBRFP05bqM/HfWZ+Y0+47iPOghEQWURZXsQGFxYEhKWJHQg+9rZO0uv6Z3ez++PqoQmdNIV0tW3ls/reerpqrq3qr4n1Xw4fe6595hzDhERiRxxXhcgIiJnRsEtIhJhFNwiIhFGwS0iEmEU3CIiEUbBLSISYRTc4hkz+6yZ/XcQ+yWb2XYzKwhBDb83s+8P03vlm9kOM0sJYt+fmdnnhuNzJfYouMUTZpYEfAf48VD7Oue6gHuB/xvqus7SN4HfOec6g9j3x8C3A/8OImdEwS1euRrY7pw7FOT+fwRuNrPkENb0rgXquhl4IJj9nXNHgO3AB0NZl0QnBbeEhJl93cweO+m5Xw0YGnkf8OKAbdeZ2R4z8wUev8/MjppZPoBzrho4BiwIcd2fMbMqM2s0syfNrGTAtvcGhkKazezXZvaimX06sHk+0BSoEzPLMbNqM/tA4HF64H1vGvBxK4D3h7I9Ep0U3BIqDwBLzSwLwMwSgOuA+wPbZwI7ju/snPsz8CrwSzPLBe4BPu2cqxvwntuAcwf7MDO7wcyaTnMbO1TBZnYp8APgWqAY2A/8KbAtD3gU+BaQG6h90YCXn9yeRuBTwG8CY/M/B9Y75+4Lpj0ip5PgdQESnZxzR8xsJfBR4DfAUqDeObcusEsW0HrSy74AbMTfE33KOff0SdtbA68b7PP+iH845Wx8HLjXOfc6gJl9CzhmZmXAYmCLc+7xwLZfAv8y4LXvaI9z7h9m9gjwPP6wnxlse0RORz1uCaU/ADcG7t/IW71t8A97ZAzc2TnXBDwCzAB+Osj7ZQBNw1/mCSX4e9nH62kDGoDRgW0HB2xzQPWA176jPQHL8Lfnd865hpO2hbo9EqUU3BJKTwDnmNkM4CrgwQHbNgIVA3c2s1n4hxceAn45yPtNBTYM9kFm9nEzazvNbcihEuAwMG7Ae6bh7ykfAo4AYwZss4GPT9GeeOBu4D7gdjObGGx7RE5HwS0hE5gW9yj+IYy1zrkDAzY/Ayw5/iAw9/kB4F+BW4DRZvb5AdtHAznA6lN81oPOufTT3A4M9rqT/BG4xcxmBWaJ/Cewxjm3D/hfYKaZXRMYr/8CUDTgtWuBrECdx/1r4OengJ8A9wXC/LglwF+DqEvkbRTcEmp/wD+2e/9Jzz8FTBkwa+MHQLVz7s7AvO0bge+b2aTA9huAPwS2hYRz7nngu8Bj+HvYE4DrA9vq8Y/X/wj/8Mk0oBLoCmzvBn4fqBszmwN8FbjJOdcH/BBw+Od6Y2bFgfd4IlTtkehlWkhBQikwRLEdKHLOtZy07TZgmnPuy0O8RzL+IYXFzrnakBV7BswsDv8Y98edc8sDz+UDq4DznHNvDvH6nwK7nXO/DnmxEnUU3BIygXD7GeBzzn3K63rOlpldAawB3gS+jn+4pHyokBYZbpoOKCEROLBXg3+WxlKPyxkuC/GPgycBW4FrFNriBfW4RUQijA5OiohEmJAMleTl5bmysrJQvLWISFRat25dvXMuP5h9QxLcZWVlVFZWhuKtRUSikpntH3ovPw2ViIhEGAW3iEiEUXCLiEQYBbeISIRRcIuIRBgFt4hIhFFwi4hEmLAJ7v5+x/+8sIuVO+uG3llEJIaFTXDHxRl3r9zDC9vD4qqdIiJhK2yCG6DQl8LR5k6vyxARCWthFdxFvhRqWhXcIiKnE1bBXeBLpkY9bhGR0wqr4C7ypVDb2kV/v64RLiJyKmEV3IW+FHr7HQ3t3V6XIiIStsIuuAFqWjRcIiJyKmEW3MkA1OoApYjIKYVVcBdl+nvcR5u7PK5ERCR8hVVw56UnY6ahEhGR0wmr4E6MjyM3LVnBLSJyGmEV3ABFmQpuEZHTCbvgLsxI4WiLxrhFRE4l/II7M4Va9bhFRE4p/II7I4WG9m66evu8LkVEJCyFXXAXZfrncte1arhERGQwYRfcBTp7UkTktMIuuItOBLd63CIigwm74Nb1SkRETi/sgjs7NZGk+DiOKrhFRAYVdsFtZhT4kqnVUImIyKDCLrjBP86ttSdFRAYXlsFdqLUnRUROKejgNrN4M3vDzJ4OZUEQCG71uEVEBnUmPe4vAdtCVchAhb5k2rv7aOvqHYmPExGJKEEFt5mNAd4P/Da05fgdnxKocW4RkXcKtsf938A3gP5T7WBmt5lZpZlV1tXVnVVRx4NbF5sSEXmnIYPbzK4Cap1z6063n3NumXNurnNubn5+/lkVdXztSR2gFBF5p2B63BcAHzSzfcCfgEvN7IFQFvXWUInmcouInGzI4HbOfcs5N8Y5VwZcD7zgnLsxlEWlJSeQkZyg095FRAYRlvO4AUpzUtlb3+51GSIiYeeMgts5t8I5d1WoihloSlEG24+2jMRHiYhElLDtcU8pzqCmpYumjm6vSxERCSthG9yTi3wAbD/a6nElIiLhJWyDe0pRBgA7FNwiIm8TtsFdkJFMVmqixrlFRE4StsFtZkwuzNBQiYjIScI2uAGmFvvYebSV/n7ndSkiImEjrIN7clEG7d19HGp60+tSRETCRtgHN8C2IxrnFhE5LqyDu6JQM0tERE4W1sGdnpxAac4ottcouEVEjgvr4AaYUuRTj1tEZIAICO4M9ta309nT53UpIiJhIeyDe3JRBn39jqraNq9LEREJC2Ef3Dr1XUTk7cI+uMty00hKiGOHDlCKiAARENwJ8XFMLsxgU3Wz16WIiISFsA9ugPPLcnj9wDG6enWAUkQkIoJ7fnkOXb39bFSvW0QkQoJ7fA5msHp3g9eliIh4LiKCOys1iSlFPlbvVXCLiEREcIO/171u/zG6e/u9LkVExFMRE9wLynPp7OlnY3WT16WIiHgqYoJ7/vgcAFbv0XCJiMS2iAnu7LQkphRlsHpPo9eliIh4KmKCG/zDJZX7GzXOLSIxLcKCO4fOnn42HdI4t4jErogK7nnjcwE0XCIiMS2igjsnMM79yu56r0sREfFMRAU3wJLJ+azZ00hzR4/XpYiIeCLigvt9M4rp7Xc8v73G61JERDwRccF9zuhMijNT+Nvmo16XIiLiiYgL7rg444rpRby4s472rl6vyxERGXERF9wAV0wvoqu3nxd31nldiojIiIvI4D6/LJuctCQNl4hITBoyuM0sxczWmtkGM9tiZv9vJAo7nYT4ON4ztZAXttdqVRwRiTnB9Li7gEudc+cCs4ClZrYgtGUNbenMItq6enmlShedEpHYMmRwO7+2wMPEwM2FtKogLJqQS0ZygoZLRCTmBDXGbWbxZrYeqAWedc6tGWSf28ys0swq6+pCf9AwOSGey6YW8NfNR+js0XCJiMSOoILbOdfnnJsFjAHmmdmMQfZZ5pyb65ybm5+fP9x1DurauaW0dPaq1y0iMeWMZpU455qAFcDSkFRzhhaU5zIuN5WH1h7wuhQRkRETzKySfDPLCtwfBVwObA91YcGIizOunVvKmr2N7KlrG/oFIiJRIJgedzGw3Mw2Aq/hH+N+OrRlBe+jc8YQH2f8ufKg16WIiIyIhKF2cM5tBM4bgVrelQJfCpdOKeCxddX8y3snkxgfkecUiYgELSpS7mPzSqlv6+b5bbpioIhEv6gI7iUVBRT5UnhorYZLRCT6RUVwx8cZ188r5cWddVTVtnpdjohISEVFcAPctLCMlMQ47n5xj9eliIiEVNQEd05aEtfNLeWJ9Yc40vym1+WIiIRM1AQ3wKcvKqffwb0v7fW6FBGRkImq4C7NSeWqc4r545oDWkxYRKJWVAU3wGcXT6C9u48H1uz3uhQRkZCIuuCeVuJjSUU+v3t5Lx3dWpNSRKJP1AU3wD9fNon6tm6NdYtIVIrK4J4zLpv3Tivkrhf30Nje7XU5IiLDKiqDG+AbSyfT0d3LHcurvC5FRGRYRW1wTyzI4CNzxnD/q/upPtbhdTkiIsMmaoMb4MuXV4DBz5/d5XUpIiLDJqqDuyRrFLcsKuPxN6rZWN3kdTkiIsMiqoMb4AuXTiQvPZnvPrGZvn7PF6cXETlrUR/cvpREvvP+qWyobtbalCISFaI+uAE+eG4JC8tz+fHfd1Df1uV1OSIiZyUmgtvM+N410+no7uW//hoW6xyLiLxrMRHc4J8e+OmLynl0XTUvV9V7XY6IyLsWM8EN8KXLJlGen8Y3Ht1IS6euHigikSmmgjslMZ6ffvRcjjS/yfef3up1OSIi70pMBTfAeWOzuf3iCTxcWa1V4UUkIsVccIP/6oFTijL45uObdBEqEYk4MRncyQnx/OzaWTR39PDVh9fTrxNzRCSCxGRwg3/Bhe9+YBordtRx90qtDC8ikSNmgxvgxvljueqcYn7yjx28tq/R63JERIIS08FtZvzgn2ZSmj2KL/7xDRp0VqWIRICYDm6AjJRE7vj4bI51dHP7A6/T3dvvdUkiIqcV88ENML0kkx995BzW7mvk357cjHM6WCki4SvB6wLCxdWzRrOzppU7lu9mSpGPmxeVeV2SiMig1OMe4Gvvmcx7phXyH09v5cWddV6XIyIyKAX3AHFxxs+vm0VFYQa3P7COTdXNXpckIvIOCu6TpCcn8Idbzic7NYlbfr+W/Q3tXpckIvI2Qwa3mZWa2XIz22ZmW8zsSyNRmJcKfCncd+s8evsdN9+7VosviEhYCabH3Qt8zTk3FVgAfMHMpoW2LO9NyE/nnpvP52hLJ5+4Zy1NHbqmiYiEhyGD2zl3xDn3euB+K7ANGB3qwsLBnHHZLPvEXHbXtnHTvWt1DW8RCQtnNMZtZmXAecCaQbbdZmaVZlZZVxc9MzIWV+Rz542z2Xq4hVt+9xrtXb1elyQiMS7o4DazdOAx4MvOuZaTtzvnljnn5jrn5ubn5w9njZ67bGohv/rYeaw/2MTN966lVT1vEfFQUMFtZon4Q/tB59zjoS0pPL1vZvGJ8L7xt2s05i0inglmVokB9wDbnHM/C31J4evKmcXcdeMcth1p5fplqzXbREQ8EUyP+wLgE8ClZrY+cLsyxHWFrcunFXLPJ+eyr6Gdj971KgcbO7wuSURiTDCzSl5yzplz7hzn3KzA7ZmRKC5cXTQpnwdunU9jezf/dOcrbD38jiF/EZGQ0ZmT79Lcshwe+dxCEuKM6+5+lVd213tdkojECAX3WagozOCx2xdRlJnCTfes5eHXDnpdkojEAAX3WSrJGsWjty9i4YRcvvHYRn7wzDYtPiwiIaXgHgaZoxK595Pn8/H5Y7l75R5uu3+d5nqLSMgouIdJYnwc379mBv/+gWks31HLNXe8zO66Nq/LEpEopOAeRmbGJy8YzwO3zqepo4dr/udlnt1a43VZIhJlFNwhsHBCLk9+8ULG56fxmfsq+c9nttHTp0WIRWR4KLhDZHTWKB7+7EI+sWAcy1bu4fplqznc9KbXZYlIFFBwh1BKYjzfu2YGv/rYeWw/0sKVv1zF3zYf9bosEYlwCu4R8IFzS3jqixdSmp3K5x5Yx7ce30RHty4PKyLvjoJ7hJTnp/PY7Yv47JJy/vTaAa761UusP9jkdVkiEoEU3CMoKSGOb71vKg/eOp/O7j4+fOcr/PQfO+ju1YFLEQmegtsDiybm8bevLOZD543mVy9UcfUdL7P5ULPXZYlIhFBwe8SXkshPPnouv7lpLvVtXVx9x8v88G/b6ezp87o0EQlzCm6PvWdaIc99ZQkfnj2aO1fs5spfrNKVBkXktBTcYSAzNZEffeRc7r91Hr39jht+s4avPryeBq2wIyKDUHCHkYsm5fOPryzmC5dM4KkNh7n0py/ywOr99OlqgyIygII7zKQkxvP1K6bwzD9fxNTiDL7zxGauvuMl1u0/5nVpIhImFNxhalJhBg99ZgG/+th51Ld28+E7X+Erf17PkWadNi8S6xTcYczM+MC5JTz/tSV8/uIJ/O+mI1zykxX8/NmdOvNSJIYpuCNAWnIC31g6hee/uoTLphbyi+d3cfGPV/DQ2gP06qqDIjFHwR1BSnNSueOG2Tx2+0JKc1L51uObWPqLVfx9y1Gc0wFMkVih4I5Ac8bl8OjnFnLXjXPo73d89v51fOjXr/BKleZ/i8QCBXeEMjOWzijiH19ZzA8/PJOalk5u+O0abvjNair3NXpdnoiEkIXiT+y5c+e6ysrKYX9fObXOnj4eXHOAO1dUUd/WzeKKfL58+SRmj832ujQRCYKZrXPOzQ1qXwV3dOno7uWB1fu568U9NLZ3c+HEPL546UTml+d6XZqInIaCW2jv6uXBNftZtnIv9W1dzCvL4fOXTGBJRT5m5nV5InISBbec0NnTx0NrD7Bs5R6ONHcyvcTH7RdPYOn0IhLidYhDJFwouOUdunv7eWL9Ie5asZs99e2U5ozi0xeW89G5Y0hNSvC6PJGYp+CWU+rrdzy7tYZlK3fz+oEmMkcl8vH5Y7lpYRlFmSlelycSsxTcEpTKfY38dtVe/rH1KHFmXHVOMbdcMJ5zS7O8Lk0k5pxJcOtv5Bg2tyyHuWU5HGjo4Hev7OWRymqeWH+YWaVZ3HJBGUtnFJGcEO91mSJyEvW45YTWzh4eW1fNH17dz976dvLSk7ju/FJumD+O0VmjvC5PJKppqETOSn+/Y1VVPfe/uo/nt9diwKVTCrhh/liWVBQQH6fphCLDbViHSszsXuAqoNY5N+Nsi5PwFxdnLKnIZ0lFPgcbO3ho7QEerqzmuW2VjM4axbVzS7n2/DEUZ6oXLuKFIXvcZrYYaAPuCza41eOOPt29/Ty7tYaH1h7gpap64gyWVORz3fmlXDqlkKQEzQkXORvDPlRiZmXA0wpuATjQ0MHDlQd5ZN1Balq6yElL4kPnjeYjc8YwtdjndXkiEcmT4Daz24DbAMaOHTtn//79QRUrkau3r59VVfU8UnmQZ7fW0NPnmFbs48NzxnD1rBLy0pO9LlEkYqjHLSOusb2bpzYc5rHXq9lY3Ux8nLF4Uh4fmj2G90wtZFSSphWKnI6CWzy1q6aVx984xF/eOMTh5k7SkuK5YnoRH5xVwoUT83SNFJFBKLglLPT3O9bsbeQv6w/xzKYjtHT2kpOWxJUzi7jqnBLmleUQp6mFIsAwB7eZPQRcDOQBNcC/OefuOd1rFNxysq7ePlbsqOOpDYd5blsNnT39FGQkc+XMYq46p5jZY7MV4hLTdAKOhLX2rl6e21bDM5uOsHxHHd29/RT5Ulg6o4grZxYzZ1y2TvKRmKPglojR2tnD89tqeWbTEVbs9Id4fkYy751WyNIZRSwozyVRY+ISAxTcEpHaunp5YXstf998lOU7auno7sOXksBlUwt577RCFlfkk5as66JJdFJwS8Tr7Olj1a56/r7lKM9tq6Gpo4ekhDgunJjH5VMLuXxqAQU+XT9cooeCW6JKb18/a/c18tzWWp7ddpSDjW8CcM6YTC6bUshlUwuYXuLTWpoS0RTcErWcc+ysaeO5bTU8t62G9QebcA4KfclcMrmAS6YUcMHEPNI1pCIRRsEtMaO+rYvl22tZvqOWVTvrae3qJTHemDc+h4srCrh4cj4TC9LVG5ewp+CWmNTd20/lvkZW7KxjxY5adta0AVCSmcKSyfksnpTPool5ZI5K9LhSkXdScIsAh5reZGUgxF+uaqCtq5c4g1mlWVw0KZ+LJuUxqzRLp+BLWFBwi5ykp6+fNw40sWpXHSt31rHxUDPOQUZyAvPLc7loUh4XTMxjQn6ahlXEEwpukSE0dXTzyu4GVu2q46Wq+hMzVYp8KSyakMuiiXksmpBLidbalBGi4BY5QwcaOnipqp6Xd9fz6u4GGtu7ARiXm8qiCbksKM9lYXmu5o5LyCi4Rc5Cf79jR00rr+5u4JXdDazZ20BrZy8A5flpLCjPZf74HBaU51KoIJdhouAWGUZ9/Y4th5tZvaeBV3c3ULnvGK1d/iAvy01l3vgc5o33h/mY7FEaI5d3RcEtEkK9ff1sO9LKmr0NrNnbyNq9jTS/2QP4x8jPH5/DvLJszh+fQ0VBhi5XK0FRcIuMoP5+x87aVl7b28iavY28tq+RmpYuADJSEpgzLpu547KZMy6HWaVZWsZNBnUmwa3zgkXOUlycMaXIx5QiH59YWIZzjupjb/LavkZe23fMf1LQjjoAEuKM6SU+Zo/LZvbYbOaMy9bMFTlj6nGLjICmjm5eP3CMyn3HWLf/GBuqm+js6Qf8wyuzx2Uxe2w2543NYnpJJimJ6pXHGvW4RcJMVmoSl04p5NIphYD/hKBtR1p4ff8xXj/QxLr9x3hm01EAEuONacU+ZpVmMWtsFrNKsynLTdVBTzlBPW6RMFHb2skbB5p440AT6w8eY2N1Mx3dfQBkpSZy7pgszi3NYlZpJueMySIvPdnjimU4qcctEoEKMlK4YnoRV0wvAvyzV3bWtLGhuon1B5pYf7CJVbt20R/oa43OGsU5Y/whfu6YTGaMycSXogtoxQL1uEUiSHtXL1sOt7DhYBMbqpvYWN3MgcaOE9vL89KYMTqTmaMzmTkmk+klPjIU5hFBPW6RKJWWnBA44SfnxHPH2rvZdKiZTYea2XCwicp9jTy54fCJ7eV5aUwfncnM0T5mlGQyvSSTzFSFeSRTcItEuOy0JBZX5LO4Iv/Ec/VtXWyqbmZzINDX7WvkqQFhPiZ7VCDEfUwf7WN6SSYFGck6ABohFNwiUSgvPZlLpviXcjuuoa2LLYdb2Hy4mS2HW9h6uIW/bTk64DVJTC32Ma3Ex7RiH9NLfIzPSydeZ36GHQW3SIzITU9+R8+8tbOHbUda2XK4ma2HW9hyuIV7X9pLT5//2FdyQhxTijKYWuxjarHPf7/Ep4OgHtPBSRF5m+7efnbXtbH1cAvbjrSwNXBr6ug5sc/orFFMLc5gclEGU4p8TC3OoCw3TasJnQUdnBSRdy0pIe5ED/s45xw1LV1sO+oP8x1HW9l2pIXlO+roC8xPTEqIY2J+OlOK/IF+/FbkS9HY+TBTcIvIkMyMoswUijJTuGTyW+PmXb19VNW2seNoK9sDt5d31/P4G4dO7ONLSWByUQYVhf4gn1SQQUVhOrk6gehdU3CLyLuWnBDP9MAUw4GOtXezs6aVnTX+MN9V08ZTGw7z4JreE/vkpScxqSCDSYXpTCrMoKLA/zMnLWmkmxFxFNwiMuyy05KYX57L/PLcE88dH245Hui7atrYWdvK468foq3rrUDPTUvyh3kg1CfmpzOxMJ38dE1XPE7BLSIjYuBwy8CZLc45jjR3squ2jV2BUK+qbeOJ9YdOLBkH/iGXiQXpTCxIZ0L+Wz9Lc1JjbsqigltEPGVmlGSNoiRrFEtOCvSali6qatuoqm2lqq6NXTVtvLC9locrq0/slxQfx/i8NCYUpDEhP/3EbXx+GunJ0Rlx0dkqEYl4A3voF07Ke9u2po5udte1sbu2naq6Nqpq/dMX/7b56ImLcAEU+pKZkJ9OeX4a5Xlv/RydPSqie+kKbhGJOFmpScwZl8OccTlve76rt4/9DR3sqWtjd107u+va2FPXzpPrD9MyYNglKT6OcbmplOenMT4vnfK8NMbnpzE+L43ctKSwH0sPKrjNbCnwCyAe+K1z7r9CWpWIyLuQnBBPRaF/6uFAzjka2rvZU9fO3np/mO+pb2d3XTsvbK89caYoQEZyAmV5/hD3/0ylLNf/OCs1PGa8DBncZhYP3AG8B6gGXjOzJ51zW0NdnIjIcDAz8tKTyUtPftuVFcF/3fNDTW+yt76dPXXt7GtoZ299O68fOMZTGw8z8OTyrNREynLTKMtNpSwvjbLcNMbl+oM9KzVxxHrqwfS45wFVzrk9AGb2J+BqQMEtIhEvIT6OcblpjMtN4+LJb9/W1dvHwcYO9tZ3sK/eH+r7Gtp5bd8x/rLh7aF+/ESjhz+7MOQBHkxwjwYODnhcDcw/eSczuw24DWDs2LHDUpyIiJeSE+KZWJDBxIKMd2w7Hur7GzrY19DB/oZ2unv7R6TXHUxwD1bFO65M5ZxbBiwD/0WmzrIuEZGwdrpQD7VgLuVVDZQOeDwGOHyKfUVEJMSCCe7XgElmNt7MkoDrgSdDW5aIiJzKkEMlzrleM/s/wN/xTwe81zm3JeSViYjIoIKax+2cewZ4JsS1iIhIELRchYhIhFFwi4hEGAW3iEiEUXCLiESYkKzybmZ1wP4zeEkeUD/shYS3WGwzxGa7Y7HNEJvtPps2j3PO5Q+9W4iC+0yZWWWwy9JHi1hsM8Rmu2OxzRCb7R6pNmuoREQkwii4RUQiTLgE9zKvC/BALLYZYrPdsdhmiM12j0ibw2KMW0REghcuPW4REQmSgltEJMKMWHCb2VIz22FmVWb2zUG2J5vZnwPb15hZ2UjVFkpBtPurZrbVzDaa2fNmNs6LOofTUG0esN9HzMyZWVRMGQum3WZ2beD73mJmfxzpGodbEL/fY81suZm9Efgdv9KLOoeTmd1rZrVmtvkU283Mfhn4N9loZrOHvQjnXMhv+C8HuxsoB5KADcC0k/b5PHBX4P71wJ9HorYwaPclQGrg/u2R3u5g2hzYLwNYCawG5npd9wh915OAN4DswOMCr+segTYvA24P3J8G7PO67mFo92JgNrD5FNuvBP6Kf/WwBcCa4a5hpHrcJxYcds51A8cXHB7oauAPgfuPApfZSC2ZHDpDtts5t9w51xF4uBr/CkORLJjvGuB7wI+AzpEsLoSCafdngDucc8cAnHO1I1zjcAumzQ7wBe5nEgWrZznnVgKNp9nlauA+57cayDKz4uGsYaSCe7AFh0efah/nXC/QDOSOSHWhE0y7B7oV//+pI9mQbTaz84BS59zTI1lYiAXzXVcAFWb2spmtNrOlI1ZdaATT5n8HbjSzavzX9P/iyJTmqTP97/6MBbWQwjAIZsHhoBYljjBBt8nMbgTmAktCWlEPzoMrAAABrUlEQVTonbbNZhYH/Bz45EgVNEKC+a4T8A+XXIz/L6tVZjbDOdcU4tpCJZg2fwz4vXPup2a2ELg/0Ob+0JfnmZBn2Uj1uINZcPjEPmaWgP/PqtP9ORIJglpo2cwuB74NfNA51zVCtYXKUG3OAGYAK8xsH/4xwCej4ABlsL/jf3HO9Tjn9gI78Ad5pAqmzbcCDwM4514FUvBfiCmahXyB9ZEK7mAWHH4SuDlw/yPACy4w0h/Bhmx3YNjgbvyhHeljnjBEm51zzc65POdcmXOuDP+4/gedc5XelDtsgvkdfwL/wWjMLA//0MmeEa1yeAXT5gPAZQBmNhV/cNeNaJUj70ngpsDskgVAs3PuyLB+wggeib0S2In/KPS3A8/9B/7/aMH/hT4CVAFrgXKvjx6PULufA2qA9YHbk17XHOo2n7TvCqJgVkmQ37UBPwO2ApuA672ueQTaPA14Gf+Mk/XAe72ueRja/BBwBOjB37u+Ffgc8LkB3/MdgX+TTaH4/dYp7yIiEUZnToqIRBgFt4hIhFFwi4hEGAW3iEiEUXCLiEQYBbeISIRRcIuIRJj/Dy5RmucM+boEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from myutils.draw.math import plt_2d_functions\n",
    "\n",
    "plt_2d_functions([lambda x : -np.log(x)], x=np.arange(.01, 1+.01, .01), title='y(x) = log(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like the log just reframes the probability in an exponential context. But from it, we can identify that if the output for a particular $\\hat{p_k}^{(i)}$ is high (for the true class) then the cost is low, and vise versa. This is what we want because were defining a numerically higher cost in the context when the model is wrong and numerically lower cost when the model is correct.\n",
    "\n",
    "Now lets fill in the nested functions of the cost function and see if we can uncover anything else. I am going to remove the log because all it does is provide a exponential reinterpretation on top of the probability.\n",
    "\n",
    "$$J(W) = \\frac{exp(s_1(x))}{\\sum_{k=1}^K exp(s_k(x))}$$\n",
    "\n",
    "$$J(W) = \\frac{exp((w^k)^T \\cdot x)}{\\sum_{k=1}^K exp((w^k)^T \\cdot x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good. It tells us why the weight matrix is nessessary. It also tells us how the $\\hat{p}^k$ can return a high or low probability. Lets begin with the second point.\n",
    "\n",
    "Lets begin with $exp((w^k)^T \\cdot x)$, and see how this looks like. We know that $(w^k)^T \\cdot x$ is just the linear summation of weights on top of each feature of the input $x$.\n",
    "\n",
    "$$z = w_0 + x_1 w_1 + x_2 w_2 + x_3 w_3 + \\dots + x_n w_n = \\sum_{i=0}^n x_i w_i = x w^T$$\n",
    "\n",
    "This means that can have any real value of x. This means that can have any real value of x. The $e$ just scales this value exponentially.\n",
    "\n",
    "The expression simplifies to $\\frac{a}{b}$, where $0 \\le J(W) \\le 1$ and $a < b$ since b contains a and because we know that $J(W)$ is a normalized probability. Utimately what is happening is that if the score is high in the numerator, the the ratio grows larger and a high probability is returned. And reframing this probability back into from before, we know that it produces a lower cost.\n",
    "\n",
    "And secondly, notice how we are always just working with a particular $w$ vector, and not the matrix in its entirely. The matrix of weights is effectively a contain that we can pull $w$ vectors from. \n",
    "\n",
    "### ????\n",
    "\n",
    "Does this mean that there is a single cost function for all classes, and $W$ is just initially several points that will descend down to its the minimum? Or does this mean that there is a cost function per class and that $W$ independently indexes the correct $w$ vector per appropriate cost function?\n",
    "\n",
    "my guess is the secvond one because of the if condition from indicator\n",
    "### ???\n",
    "\n",
    "\n",
    "Finally to apply this algorithm in gradient descent is the same. We will needs its derivative. Ill include it here for reference, but will not derive it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a3d902390>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_2d_functions([lambda x: x / 10], x=np.arange(-5, 5, .25), title=r'$z(a,b) = \\frac{a}{b}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And all this is saying is that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We are describing an continuous space where given some $w$ we are saying \"what does this give us\"? Imagine we had a random initialization of $W$.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Next, recall that our cost for a single sample was defined as:\n",
    "\n",
    "$$J(w) = -[(y^{(i)}log(\\hat{y}(x^{(i)})) + (1-y^{(i)})log(\\hat{y}(x^{(i)}))]$$\n",
    "\n",
    "Where we hard listed the cancelization on one or the other class.\n",
    "\n",
    "In the multinomial case,\n",
    "\n",
    "$$J(W) = -\\sum_{j=1}^K 1\\{y^{(i)}=j\\}log(\\hat{y_k}(x^{(i)})$$\n",
    "\n",
    "\n",
    "\n",
    "Finally, we can derive the gradient descent step also similiarly to the binary case\n",
    "\n",
    "$$\\nabla w_j = \\frac{1}{m} \\sum_{i=0}^m (-1\\{y^{(i)}=j\\} + \\hat{y_k}(x^{(i)}))x^{(i)}$$\n",
    "\n",
    "which after every iteration step, all $w_j$ weight vectors get updated. After training, we will finally make our classification $\\hat{y_k}$ by selecting the classification that gives rise to the greatest probability. In other words, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logisitic Regression with Newgroup Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /Users/danielm/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/danielm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/danielm/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# data source code adapted from NLTK chapter\n",
    "import nltk\n",
    "nltk.download('names')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "groups = fetch_20newsgroups()\n",
    "NAMES = set(names.words())\n",
    "\n",
    "def my_filter(post):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    f1 = [word.lower() for word in nltk.tokenize.word_tokenize(post)]\n",
    "    f2 = [word for word in f1 if word.isalpha() and word not in NAMES]\n",
    "    return ' '.join(lemmatizer.lemmatize(word) for word in f2)\n",
    "\n",
    "\n",
    "cleaned_posts = []\n",
    "for post in groups.data:\n",
    "    cleaned_posts.append(my_filter(post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# vectorize and then split the data\n",
    "tfidfv = TfidfVectorizer(sublinear_tf=True, \n",
    "                         max_df=0.5, \n",
    "                         stop_words='english', \n",
    "                         max_features=40000)\n",
    "vect_posts = tfidfv.fit_transform(cleaned_posts)\n",
    "X_train, X_test, y_train, y_test = train_test_split(vect_posts, groups.target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielm/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters discovered:\n",
      "{'alpha': 1e-06, 'eta0': 10, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "# grid search iteratables\n",
    "parameters = {'penalty': ['l2', None], \n",
    "              'alpha': [1e-07, 1e-06, 1e-05, 1e-04], \n",
    "              'eta0': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "# now perform the model algorithm\n",
    "sgd_lr = SGDClassifier(loss='log', learning_rate='constant', eta0=0.01, fit_intercept=True, max_iter=10)\n",
    "grid_search = GridSearchCV(sgd_lr, parameters, n_jobs=-1, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best model parameters discovered:')\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our model is: 91.5104445634708%\n"
     ]
    }
   ],
   "source": [
    "sgd_lr_best = grid_search.best_estimator_\n",
    "accuracy = sgd_lr_best.score(X_test, y_test)\n",
    "print(f'The accuracy of our model is: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo\n",
    "\n",
    "# what is the relationship between logistic regression and neural networks?\n",
    "# explain why alternative loss parameter functions can be used (not just log)\n",
    "# deper dive into how the vector algebra works (equivalent dot product with summations)\n",
    "# testing the performance of a classifier with random forest decision tree important features (subset on the data with\n",
    "# these features, and see how they perform.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
