{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "Exhaustively fine tuning each algorithm can be very time consuming. However, the question still stands: \"Which model should I chose?\". We can answer this question by first understanding the data.\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "* Is online learning required? I other words, is the model going to update in real time, with real sequential streams of information? Or is the learning take place batch-level, where all of the learning takes place in one go?\n",
    "\n",
    "\n",
    "**Exploratory Data Analysis**\n",
    "\n",
    "* What is the size and dimension (shape) of the training dataset?\n",
    "* Is the data is linearly separable?\n",
    "* Are features are independent?\n",
    "\n",
    "\n",
    "## Comparison of all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | model               | use when                       | advantages                     | disadvantages                  |\n",
      "|---:|:--------------------|:-------------------------------|:-------------------------------|:-------------------------------|\n",
      "|  0 | naive bayes         | small data with independent    | fast low variance              | high bias                      |\n",
      "|    |                     | features large data without    |                                |                                |\n",
      "|    |                     | feature independence           |                                |                                |\n",
      "|  1 | logistic regression | data is ~ linearly seperable,  | scalable with SGD optimization | high variance doesnt perform   |\n",
      "|    |                     | or seperable after             | low bias                       | well with highly dimensional   |\n",
      "|    |                     | tranformation                  |                                | dataset                        |\n",
      "|  2 | svm                 | high dimensional dataset       | on par with logistic           | parameter tuning can be        |\n",
      "|    |                     | (equip with nonlinear kernal   | regression with a linear       | successful but will require a  |\n",
      "|    |                     | such as RBF)                   | kernal                         | lot of computational power and |\n",
      "|    |                     |                                |                                | memory                         |\n",
      "|  3 | random forest       | linear seperablilty is an      | categorical features do not    |                                |\n",
      "|    |                     | issue with other algorithms    | require encoding easy to       |                                |\n",
      "|    |                     |                                | explain to nonpractitioners    |                                |\n",
      "|  4 | nueral networks     | you have a lot of data and you | provably powerful (esp. deep   | finding the correct topology   |\n",
      "|    |                     | know what you are doing        | learning)                      | (layer structure) is difficult |\n",
      "|    |                     |                                |                                | computationally expensive and  |\n",
      "|    |                     |                                |                                | time consuming                 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import textwrap\n",
    "from collections import OrderedDict as d\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def wrap(d, width=30):\n",
    "    for k, v in d.items():\n",
    "        d[k] = '\\n'.join(textwrap.wrap(v, width=width)) \n",
    "    return d\n",
    "\n",
    "\n",
    "model_comp = [wrap(d({'model': 'naive bayes', \n",
    "                      'use when': 'small data with independent features\\n'\n",
    "                                  'large data without feature independence', \n",
    "                      'advantages': 'fast\\n'\n",
    "                                    'low variance\\n', \n",
    "                      'disadvantages': 'high bias'})),\n",
    "              wrap(d({'model': 'logistic regression', \n",
    "                      'use when': 'data is ~ linearly seperable, or seperable after tranformation', \n",
    "                      'advantages': 'scalable with SGD optimization\\n'\n",
    "                                    'low bias\\n', \n",
    "                      'disadvantages': 'high variance\\n'\n",
    "                                       'doesnt perform well with highly dimensional dataset'})),\n",
    "             wrap(d({'model': 'svm', \n",
    "                     'use when': 'high dimensional dataset (equip with nonlinear kernal such as RBF)', \n",
    "                     'advantages': 'on par with logistic regression with a linear kernal\\n',\n",
    "                     'disadvantages': 'parameter tuning can be successful but will require a lot of computational power and memory'})),\n",
    "             wrap(d({'model': 'random forest', \n",
    "                     'use when': 'linear seperablilty is an issue with other algorithms\\n', \n",
    "                     'advantages': 'categorical features do not require encoding\\n'\n",
    "                                   'easy to explain to nonpractitioners',\n",
    "                     'disadvantages': ''})),\n",
    "             wrap(d({'model': 'nueral networks', \n",
    "                     'use when': 'you have a lot of data and you know what you are doing', \n",
    "                     'advantages': 'provably powerful (esp. deep learning)',\n",
    "                     'disadvantages': 'finding the correct topology (layer structure) is difficult\\n'\n",
    "                                      'computationally expensive and time consuming\\n'})),\n",
    "             ]\n",
    "\n",
    "\n",
    "model_comp_df = pd.DataFrame(model_comp)\n",
    "print(tabulate(model_comp_df, headers='keys', tablefmt='pipe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sdaokdsoak',\n",
       " 'sdokaosdko',\n",
       " 'aksdokasod',\n",
       " 'koaskdpjkd',\n",
       " 'saghjahfgi',\n",
       " 'uhaighoifa',\n",
       " 'hgoiudfhio',\n",
       " 'ughfdosiuh',\n",
       " 'gifudhsgiu',\n",
       " 'sdfhiuoghd',\n",
       " 'fsiouhgius',\n",
       " 'fhgiuhsdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
