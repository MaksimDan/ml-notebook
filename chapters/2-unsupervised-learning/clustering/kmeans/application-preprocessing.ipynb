{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application - Preprocessing\n",
    "\n",
    "KMeans can also be used as a dimensionality reduction technique built on top of another machine learning model. We'll demonstrate this with the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify a baseline accuracy with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755555555555555"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(solver='liblinear', multi_class='auto', random_state=40)\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will feed in the logistic regression model then input of a reduced feature space of 50 features. It does this by taking the `fit_transform`ation from the KMeans model.\n",
    "\n",
    "More specifically, `fit_transform` on KMeans will take identify the `k` centroids by fitting the model, and then transforming each instance in `X` by casting it to the cluster-distance space. The cluster-distance space is an array for each instance in X is `[distance(c) for c in all_clusters]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"kmeans\", KMeans(n_clusters=60)),\n",
    "    (\"log_reg\", LogisticRegression(solver='liblinear', multi_class='auto', random_state=40)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96 to 98. Not bad. Note that it is intuitive to that that 10 clusters would be optimal. This is an example where our intuition fails us. While it is true that there are 10 digits, there are only 10 clusters if each digit was drawn exactly the same way, and as we know there are certainly more than 10 different ways to write digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve what we've done here by not arbitrarily chosing k. Using gridsearch, we can optimize k in the context of the logistic regression model. Note that using the silhouette score for optimizing k is unnessessary because evaluation takes place on the logistic regression model and we want to bring both into account here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 98 candidates, totalling 294 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 294 out of 294 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9822222222222222"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "grid_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
