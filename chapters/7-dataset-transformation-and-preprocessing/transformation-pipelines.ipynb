{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation Pipelines\n",
    "\n",
    "Pipelines are a sequence (order) of transformations on a dataset. Tranformers can be prebuilt, or customary (see [customa transformers]()).  All estimators but the last must be tranformers, or have the `fit_transform()` method.\n",
    "\n",
    "The pipelines `fit()` method will call `fit_transform()` to all transformers in the pipeline. The input of the previous transformer, with exception to the first is passed in as the input to the next transformor. On the last estimator, it will just call the `fit()` method.\n",
    "\n",
    "# Custom Transformers\n",
    "\n",
    "A clean and complete transformation pipeline is specific to your dataset. Because of this, custom transformers are often required. And if we want our transformers to work seamlessly with skleanrs pipeline utilities, we are required to write the tranformer customary to sklearn interface via duck-typing. Well defined transformers will allow you to automate the process of building a optimized model as well as one that is self sufficient as new data elements come in.\n",
    "\n",
    "In duck-typing, \"If it walks like a duck and it quacks like a duck, then it must be a duck\". In otherwords, if it has a `fit()` , `transform()` and `fit_transform()`, then it must be a transformer. Note: we can obtain `fit_transform` via inheritance from `TransformerMixin` and additional methods suchs as `get_params()` and `set_params()` from `BaseEstimator`.\n",
    "\n",
    "\n",
    "## Example Custom Transformer\n",
    "\n",
    "Here is an example custom transformer. It has one tunable hyperparameter, `add_bedrooms_per_room`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # feature engineering\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "# housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This net custom tranformer is built to be able to handle dataframes directly, since native tranformers work with numpy-type ndarrays. So by directly passing in a dataframe through this transformer first, we can deal with dataframes directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Pipelines\n",
    "\n",
    "Suppose you have two different datasets, or you have want to be able to transform two or more data subsets of the same dataframe differently. We can achieve this by building two or more pipelines, and then combining the pipelines that will eventually come to represent our finally dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.678351</td>\n",
       "      <td>0.093403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.510613</td>\n",
       "      <td>59.640170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.253943</td>\n",
       "      <td>23.555079</td>\n",
       "      <td>30.025447</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A          B          C  D  E\n",
       "0  69.678351   0.093403        NaN  F  C\n",
       "1  53.510613  59.640170        NaN  X  B\n",
       "2  68.253943  23.555079  30.025447  C  B"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from myutils.data import random\n",
    "\n",
    "sample_df = random.df(n_num=3, n_cat=2, n_rows=50, p_empty=.33)\n",
    "sample_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "num_attribs = ['A', 'B', 'C']\n",
    "cat_attribs = ['D', 'E']\n",
    "\n",
    "# build two pipelines, one for the numerical, and another for the catagorical\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ('one_hot_encoder', OneHotEncoder()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 37)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "# join the pipelines for form the final dataset\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline),\n",
    "])\n",
    "\n",
    "final_matrix = full_pipeline.fit_transform(sample_df)\n",
    "\n",
    "# note that the shape changed from the original 5 due to the one hot encoder\n",
    "final_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
