{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling with Test Train Split\n",
    "\n",
    "\n",
    "## The Problem with Random Sampling\n",
    "\n",
    "Consider this example. You have 5 red balls, 2 green balls and 3 blue balls. If you wanted a fair representation of the population of the 10 balls from 5 samples, you would expect to have 1/2 to red, 1/5 to be green, and the remaining to be blue. With random sampling without replacement, this what we generally get in the long term. In the immediate term, however this is not guareenteed.\n",
    "\n",
    "Introduce stratified sampling. In stratified sampling the population into homogenious subgroups called stravata, and the from each strata - the right number of instacne is sampling in order to _guarentee_ (key word here) that the samples are representative of the entire population.\n",
    "\n",
    "In our case, our strata would be: red, green, blue. And from each strata would would randomly sample the following if we wanted to ensure that we sample at least $\\leq 5$ balls.\n",
    "\n",
    "$\n",
    "\\text{red: }  \\lfloor 5/10*5 \\rfloor = 2 \\\\\n",
    "\\text{green: }\\lfloor 2/10*5 \\rfloor = 1 \\\\\n",
    "\\text{blue: } \\lfloor 3/10*5 \\rfloor = 1 \\\\\n",
    "$\n",
    "\n",
    "**What About Numerical Attributes?**\n",
    "\n",
    "In this case, we could _bin_ or _discretize_ the numerical data into groups and then stratify each group. We can do this for attributes that we know are particularly important, and will therefore want to make sure the attribute is well represented. There are a couple of strategies for doing this one way is the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "normal_matrix = np.random.normal(0, 10, (1000, 2))\n",
    "sample_df = pd.DataFrame(normal_matrix, columns=['A', 'B'])\n",
    "sample_df.hist(bins=50, figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.868593</td>\n",
       "      <td>-11.303856</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.278019</td>\n",
       "      <td>8.378370</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.771069</td>\n",
       "      <td>-9.245524</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A          B    C\n",
       "0   6.868593 -11.303856 -2.0\n",
       "1  -1.278019   8.378370  3.0\n",
       "2 -10.771069  -9.245524 -2.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now in a similiar way we have discritized the values into bins, we can create a new column of data\n",
    "# that mocks this is a perminate way\n",
    "\n",
    "# ensure to ceil to discritize float\n",
    "sample_df['C'] = np.ceil(sample_df['B'] / 4)\n",
    "sample_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, -1.0, -7.0, -6.0, -5.0, -4.0, -3.0, -2.0]\n"
     ]
    }
   ],
   "source": [
    "# possible numerical categorics now include\n",
    "print(list(set(sample_df['C'].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we want to prove by example is that stratified sampling represents the population better and with less error when compared to random sampling. To do this, we compare the stratified and random sampled proportion to true proportion of in the samplied category field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>stratified</th>\n",
       "      <th>random</th>\n",
       "      <th>random_error</th>\n",
       "      <th>statified_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-7.0</th>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-6.0</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-5.0</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-4.0</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3.0</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2.0</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>0.146</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.0</th>\n",
       "      <td>0.147</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.170</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.128</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.091</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       true  stratified  random  random_error  statified_error\n",
       "-7.0  0.002         NaN     NaN           NaN              NaN\n",
       "-6.0  0.007       0.002   0.002         0.005            0.005\n",
       "-5.0  0.020       0.004   0.006         0.014            0.016\n",
       "-4.0  0.032       0.006   0.010         0.022            0.026\n",
       "-3.0  0.055       0.011   0.010         0.045            0.044\n",
       "-2.0  0.100       0.020   0.019         0.081            0.080\n",
       "-1.0  0.146       0.029   0.034         0.112            0.117\n",
       "-0.0  0.147       0.030   0.026         0.121            0.117\n",
       " 1.0  0.170       0.034   0.024         0.146            0.136\n",
       " 2.0  0.128       0.026   0.029         0.099            0.102\n",
       " 3.0  0.091       0.018   0.015         0.076            0.073\n",
       " 4.0  0.057       0.011   0.010         0.047            0.046\n",
       " 5.0  0.022       0.004   0.007         0.015            0.018\n",
       " 6.0  0.015       0.003   0.006         0.009            0.012\n",
       " 7.0  0.008       0.002   0.002         0.006            0.006"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# random sampling\n",
    "train_set_rand, test_set_rand = train_test_split(sample_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# stratified sampling\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(sample_df, sample_df['C']):\n",
    "    train_set_strat, test_set_strat = sample_df.loc[train_index], sample_df.loc[test_index]\n",
    "\n",
    "# build the revealing the results\n",
    "compare_props = pd.DataFrame({\n",
    "    \"true\": sample_df['C'].value_counts() / len(sample_df),\n",
    "    \"stratified\": test_set_strat['C'].value_counts() / len(sample_df),\n",
    "    \"random\": test_set_rand['C'].value_counts() / len(sample_df)\n",
    "}).sort_index()\n",
    "\n",
    "compare_props[\"random_error\"] = abs(compare_props['random'] - compare_props['true'])\n",
    "compare_props[\"statified_error\"] = abs(compare_props['stratified'] - compare_props['true'])\n",
    "compare_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_error_random 0.798\n",
      "total_error_statified 0.7979999999999999\n"
     ]
    }
   ],
   "source": [
    "total_error_random, total_error_statified = compare_props['random_error'].sum(), compare_props['statified_error'].sum()\n",
    "print('total_error_random', total_error_random)\n",
    "print('total_error_statified', total_error_statified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Implementation Challenges**\n",
    "\n",
    "If we have a small dataset which catagorical variables, this would be a thing to keep in mind. Another challenge to keep in mind is, random seeding in the context where the dataset can grow. Here, we would only want the new data to be assigned randomly, while the earlier data is seeded in the same way. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
