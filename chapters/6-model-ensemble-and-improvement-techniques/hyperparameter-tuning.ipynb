{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "\n",
    "## Grid Search CV\n",
    "\n",
    "Grid search runs all possible combinations of hyperparameters onto a model and validate the results using cross-validation. It is not always feasable given the time constraints, but with it you can always modify the granularity of the parameter space. For example, we can use consequtive powers of 10, or less for more grainilarity.\n",
    "\n",
    "Grid search does not guarentee optimization of the defined estimator. It only guarentees an optimization of the defined parameter grid. Also note, if `refit` parameter is set to true (as default) it will refit to the entire training set once the optimized parameters are found. This is generally a good idea because the model would only be otherwise fit according to cross validated parameters. Adding more data is like to improve the overall performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielm/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "dataset = datasets.load_diabetes()\n",
    "X, y = dataset.data, dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Results\n",
    "\n",
    "* `best_params_` - the selection of parameters defined from the parameter grid\n",
    "* `best_estimator_` - including defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 4, 'n_estimators': 30}\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=30, n_jobs=None, oob_score=False,\n",
      "           random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_, end='\\n\\n')\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search also comes along with many measured attributes that were accumulated in the search process within `cv_results_`. We can use this as the datasource into understanding how the estimated parameters changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 3}</td>\n",
       "      <td>-4208.587037</td>\n",
       "      <td>-5282.414313</td>\n",
       "      <td>...</td>\n",
       "      <td>-4703.358859</td>\n",
       "      <td>400.680922</td>\n",
       "      <td>16</td>\n",
       "      <td>-1177.058380</td>\n",
       "      <td>-1219.181435</td>\n",
       "      <td>-1422.753399</td>\n",
       "      <td>-1239.068917</td>\n",
       "      <td>-1173.386310</td>\n",
       "      <td>-1246.289688</td>\n",
       "      <td>91.688947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009617</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 10}</td>\n",
       "      <td>-3322.445833</td>\n",
       "      <td>-4795.341864</td>\n",
       "      <td>...</td>\n",
       "      <td>-3880.621622</td>\n",
       "      <td>554.871230</td>\n",
       "      <td>10</td>\n",
       "      <td>-659.387203</td>\n",
       "      <td>-585.610886</td>\n",
       "      <td>-825.062025</td>\n",
       "      <td>-688.465612</td>\n",
       "      <td>-691.871013</td>\n",
       "      <td>-690.079348</td>\n",
       "      <td>77.565204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017478</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 30}</td>\n",
       "      <td>-3310.732630</td>\n",
       "      <td>-3959.101864</td>\n",
       "      <td>...</td>\n",
       "      <td>-3464.835533</td>\n",
       "      <td>264.065922</td>\n",
       "      <td>2</td>\n",
       "      <td>-509.478884</td>\n",
       "      <td>-484.545312</td>\n",
       "      <td>-575.314759</td>\n",
       "      <td>-570.353821</td>\n",
       "      <td>-537.190717</td>\n",
       "      <td>-535.376699</td>\n",
       "      <td>34.860479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.002772      0.000782         0.000644        0.000180   \n",
       "1       0.009617      0.002998         0.001080        0.000192   \n",
       "2       0.017478      0.000388         0.001491        0.000072   \n",
       "\n",
       "  param_max_features param_n_estimators param_bootstrap  \\\n",
       "0                  2                  3             NaN   \n",
       "1                  2                 10             NaN   \n",
       "2                  2                 30             NaN   \n",
       "\n",
       "                                    params  split0_test_score  \\\n",
       "0   {'max_features': 2, 'n_estimators': 3}       -4208.587037   \n",
       "1  {'max_features': 2, 'n_estimators': 10}       -3322.445833   \n",
       "2  {'max_features': 2, 'n_estimators': 30}       -3310.732630   \n",
       "\n",
       "   split1_test_score       ...         mean_test_score  std_test_score  \\\n",
       "0       -5282.414313       ...            -4703.358859      400.680922   \n",
       "1       -4795.341864       ...            -3880.621622      554.871230   \n",
       "2       -3959.101864       ...            -3464.835533      264.065922   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0               16        -1177.058380        -1219.181435   \n",
       "1               10         -659.387203         -585.610886   \n",
       "2                2         -509.478884         -484.545312   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0        -1422.753399        -1239.068917        -1173.386310   \n",
       "1         -825.062025         -688.465612         -691.871013   \n",
       "2         -575.314759         -570.353821         -537.190717   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0      -1246.289688        91.688947  \n",
       "1       -690.079348        77.565204  \n",
       "2       -535.376699        34.860479  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame(grid_search.cv_results_).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can individually look at the mean score and parameters as a result of each cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.86038737169817 {'max_features': 2, 'n_estimators': 3}\n",
      "61.407704585275226 {'max_features': 2, 'n_estimators': 10}\n",
      "59.71343089145715 {'max_features': 2, 'n_estimators': 30}\n",
      "61.85193438193171 {'max_features': 4, 'n_estimators': 3}\n",
      "62.45619248505091 {'max_features': 4, 'n_estimators': 10}\n",
      "59.21863299666748 {'max_features': 4, 'n_estimators': 30}\n",
      "65.76869902751439 {'max_features': 6, 'n_estimators': 3}\n",
      "62.141164491215676 {'max_features': 6, 'n_estimators': 10}\n",
      "59.6739232904195 {'max_features': 6, 'n_estimators': 30}\n",
      "69.38288142066625 {'max_features': 8, 'n_estimators': 3}\n",
      "60.997227728320084 {'max_features': 8, 'n_estimators': 10}\n",
      "59.27140624574677 {'max_features': 8, 'n_estimators': 30}\n",
      "70.19185955042897 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "61.489026157826224 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "66.77991226170997 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "61.848008718409304 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "66.81453758301731 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "61.97928026713792 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Extensions\n",
    "\n",
    "In addition to fine tuning parameters library-defined hyper parameters, we can also use to exhaustively search customly defined transformers. These tranformers can include anything, so the search space as a result can be entirely built from our imaginations. Options can include:\n",
    "\n",
    "* Optimized and exhaustive feature selection.\n",
    "* Handle outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "\n",
    "Grid Seach exhaustive meaning it may take a while to run depending the sparsity of the search space, size of the data, and the estimator involved.\n",
    "\n",
    "In comes `RandomizedSearch`. With randomized search, the number of iterations are set. Then within each iteration a random hyper parameter is selected from the parameter grid. For example, with 1000 iterations we can randomly select 1000 sets of hyperparameter combinations. This way, we can both progressively see and chosen how much computation resource are we willing to trade off for a better result.\n",
    "\n",
    "Mathematically, we can think that as the number of iterations approach infinity `RandomizedSearch` the more it becomes like `GridSearch` in a probabilistic sense. We can achieve the some computational complexity by iterating through the parameter space recursively and then stop once we set a time out, but the idea of doing a random comparison is that it increases the odds finding something more prominant. Take for instance the number of estimators as a hyper parameter. There is a greater likelihood that in general the difference between the score of a `estimators=10` and `estimators=11` is smaller than that of `estimators=10` and `estimators=not(11 or 9)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
